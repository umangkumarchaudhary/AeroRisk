"""
AeroRisk - FastAPI Main Application
====================================
Production-grade REST API for aviation safety analytics.

Author: Umang Kumar
Date: 2024-01-15
"""

import os
import sys
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__)))))

from fastapi import FastAPI, HTTPException, Query, Depends
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse
from contextlib import asynccontextmanager
import pandas as pd
import numpy as np
import joblib
from datetime import datetime, timedelta
from typing import List, Optional
import logging

# Import schemas
from src.api.schemas import (
    RiskPredictionRequest, RiskPredictionResponse,
    SeverityClassificationRequest, SeverityClassificationResponse,
    AnomalyDetectionRequest, AnomalyDetectionResponse,
    RecommendationRequest, RecommendationResponse, RecommendationItem,
    WhatIfScenarioRequest, WhatIfScenarioResponse, WhatIfScenarioResult,
    AnalyticsQueryRequest, AnalyticsDashboard, IncidentSummary,
    TrendData, TrendAnalysis, RiskDistribution,
    HealthCheckResponse, SeverityLevel, Priority
)

# Import database
from src.database.connection import engine
from sqlalchemy import text

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


# ============================================
# Global Model Storage
# ============================================

class ModelStore:
    """Store for loaded ML models."""
    risk_predictor = None
    severity_classifier = None
    anomaly_detector = None
    anomaly_scaler = None
    risk_features = []
    
    @classmethod
    def load_models(cls):
        """Load all ML models, downloading from Hugging Face if not found locally."""
        models_dir = os.path.join(os.path.dirname(__file__), '..', '..', 'models')
        os.makedirs(models_dir, exist_ok=True)
        
        # Try to import Hugging Face model loader
        try:
            from src.utils.model_loader import load_model, load_features, ensure_models_downloaded
            
            # Download models if not present
            logger.info("Checking for models (will download from Hugging Face if needed)...")
            result = ensure_models_downloaded()
            logger.info(f"Models ready: {result.get('success', [])}")
            
            # Load Risk Predictor
            cls.risk_predictor = load_model("risk_predictor")
            if cls.risk_predictor:
                logger.info("Loaded risk predictor model")
            
            # Load Risk Features
            cls.risk_features = load_features("risk_features")
            
            # Load Severity Classifier
            cls.severity_classifier = load_model("severity_classifier")
            if cls.severity_classifier:
                logger.info("Loaded severity classifier model")
            
            # Load Anomaly Detector
            cls.anomaly_detector = load_model("anomaly_detector")
            if cls.anomaly_detector:
                logger.info("Loaded anomaly detector model")
            
            # Load Anomaly Scaler
            cls.anomaly_scaler = load_model("anomaly_scaler")
            if cls.anomaly_scaler:
                logger.info("Loaded anomaly scaler")
                
        except ImportError:
            logger.warning("Hugging Face model loader not available, loading from local files only")
            cls._load_local_models(models_dir)
    
    @classmethod
    def _load_local_models(cls, models_dir):
        """Fallback: Load models from local directory."""
        # Risk Predictor
        risk_path = os.path.join(models_dir, 'xgboost_risk_predictor_v1.pkl')
        if os.path.exists(risk_path):
            cls.risk_predictor = joblib.load(risk_path)
            logger.info("Loaded risk predictor model (local)")
        
        # Load risk features
        features_path = os.path.join(models_dir, 'xgboost_risk_features.txt')
        if os.path.exists(features_path):
            with open(features_path) as f:
                cls.risk_features = f.read().strip().split('\n')
        
        # Severity Classifier
        severity_path = os.path.join(models_dir, 'lightgbm_severity_classifier_v1.pkl')
        if os.path.exists(severity_path):
            cls.severity_classifier = joblib.load(severity_path)
            logger.info("Loaded severity classifier model (local)")
        
        # Anomaly Detector
        anomaly_path = os.path.join(models_dir, 'isolation_forest_anomaly_v1.pkl')
        if os.path.exists(anomaly_path):
            cls.anomaly_detector = joblib.load(anomaly_path)
            logger.info("Loaded anomaly detector model (local)")
        
        # Anomaly Scaler
        scaler_path = os.path.join(models_dir, 'anomaly_scaler.pkl')
        if os.path.exists(scaler_path):
            cls.anomaly_scaler = joblib.load(scaler_path)
            logger.info("Loaded anomaly scaler (local)")


# ============================================
# Lifespan Context Manager
# ============================================

@asynccontextmanager
async def lifespan(app: FastAPI):
    """Startup and shutdown events."""
    # Startup
    logger.info("Starting AeroRisk API...")
    ModelStore.load_models()
    logger.info("Models loaded successfully")
    yield
    # Shutdown
    logger.info("Shutting down AeroRisk API...")


# ============================================
# FastAPI Application
# ============================================

app = FastAPI(
    title="AeroRisk API",
    description="""
    ðŸ›« **AeroRisk Aviation Safety Analytics Platform**
    
    A comprehensive API for aviation safety risk prediction, analysis, and recommendations.
    
    ## Features
    
    * **Risk Prediction** - Predict flight risk scores using XGBoost
    * **Severity Classification** - Classify incident severity with LightGBM
    * **Anomaly Detection** - Detect unusual operational patterns
    * **Safety Recommendations** - Get actionable safety recommendations
    * **What-If Analysis** - Simulate different scenarios
    * **Analytics Dashboard** - Comprehensive safety analytics
    
    ## Models
    
    | Model | Type | Purpose |
    |-------|------|---------|
    | XGBoost | Regressor | Risk score prediction (0-100) |
    | LightGBM | Classifier | Severity classification (4 classes) |
    | Isolation Forest | Detector | Anomaly detection |
    
    ## SMS Alignment
    
    All recommendations align with ICAO SMS (Safety Management System) pillars.
    """,
    version="1.0.0",
    docs_url="/docs",
    redoc_url="/redoc",
    lifespan=lifespan
)

# CORS middleware
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)


# ============================================
# Health & Status Endpoints
# ============================================

@app.get("/", tags=["Health"])
async def root():
    """Root endpoint with API info."""
    return {
        "name": "AeroRisk API",
        "version": "1.0.0",
        "status": "running",
        "docs": "/docs"
    }


@app.get("/health", response_model=HealthCheckResponse, tags=["Health"])
async def health_check():
    """Health check endpoint."""
    models_loaded = []
    if ModelStore.risk_predictor:
        models_loaded.append("risk_predictor")
    if ModelStore.severity_classifier:
        models_loaded.append("severity_classifier")
    if ModelStore.anomaly_detector:
        models_loaded.append("anomaly_detector")
    
    # Check database
    db_status = "disconnected"
    try:
        with engine.connect() as conn:
            conn.execute(text("SELECT 1"))
            db_status = "connected"
    except:
        pass
    
    return HealthCheckResponse(
        status="healthy" if db_status == "connected" else "degraded",
        version="1.0.0",
        database=db_status,
        models_loaded=models_loaded
    )


# ============================================
# Prediction Endpoints
# ============================================

@app.post("/api/v1/predict/risk", response_model=RiskPredictionResponse, tags=["Predictions"])
async def predict_risk(request: RiskPredictionRequest):
    """
    Predict flight risk score (0-100).
    
    Uses XGBoost model trained on historical incident data.
    Higher scores indicate higher risk.
    """
    if ModelStore.risk_predictor is None:
        raise HTTPException(status_code=503, detail="Risk predictor model not loaded")
    
    # Prepare features
    features = {
        'incident_year': request.incident_year,
        'incident_month': request.incident_month,
        'incident_day_of_week': request.incident_day_of_week,
        'is_weekend': request.is_weekend,
        'severity_code': request.severity_code,
        'phase_risk_factor': request.phase_risk_factor,
        'total_injuries': request.total_injuries,
        'injury_rate': request.injury_rate,
        'has_coordinates': request.has_coordinates,
        'is_us': request.is_us,
        'weather_risk_score': request.weather_risk_score,
    }
    
    # Filter to available features
    available = {k: v for k, v in features.items() if k in ModelStore.risk_features}
    df = pd.DataFrame([available])
    
    # Ensure all required features exist
    for feat in ModelStore.risk_features:
        if feat not in df.columns:
            df[feat] = 0
    
    df = df[ModelStore.risk_features]
    
    # Predict
    risk_score = float(ModelStore.risk_predictor.predict(df)[0])
    risk_score = max(0, min(100, risk_score))  # Clamp to 0-100
    
    # Determine risk level
    if risk_score >= 75:
        risk_level = "CRITICAL"
    elif risk_score >= 50:
        risk_level = "HIGH"
    elif risk_score >= 25:
        risk_level = "MEDIUM"
    else:
        risk_level = "LOW"
    
    return RiskPredictionResponse(
        risk_score=round(risk_score, 2),
        risk_level=risk_level,
        confidence=0.85,
        model_version="v1.0"
    )


@app.post("/api/v1/predict/severity", response_model=SeverityClassificationResponse, tags=["Predictions"])
async def predict_severity(request: SeverityClassificationRequest):
    """
    Classify incident severity into 4 categories.
    
    Categories:
    - NONE: No injuries
    - MINOR: Minor injuries
    - SERIOUS: Serious injuries
    - FATAL: Fatalities
    """
    if ModelStore.severity_classifier is None:
        raise HTTPException(status_code=503, detail="Severity classifier not loaded")
    
    # Prepare features (simplified for demo)
    features = pd.DataFrame([{
        'weather_risk_score': request.weather_risk_score,
        'crew_fatigue_index': request.crew_fatigue_index,
        'maintenance_risk': request.maintenance_risk,
        'visibility_m': request.visibility_m,
        'wind_speed_kt': request.wind_speed_kt,
    }])
    
    # Predict
    try:
        prediction = int(ModelStore.severity_classifier.predict(features)[0])
        probabilities = ModelStore.severity_classifier.predict_proba(features)[0]
    except:
        # If features don't match, return default
        prediction = 0
        probabilities = [0.7, 0.2, 0.07, 0.03]
    
    severity_map = {0: "NONE", 1: "MINOR", 2: "SERIOUS", 3: "FATAL"}
    
    return SeverityClassificationResponse(
        predicted_severity=SeverityLevel(severity_map.get(prediction, "NONE")),
        severity_code=prediction,
        probabilities={
            "NONE": round(float(probabilities[0]), 4),
            "MINOR": round(float(probabilities[1]) if len(probabilities) > 1 else 0, 4),
            "SERIOUS": round(float(probabilities[2]) if len(probabilities) > 2 else 0, 4),
            "FATAL": round(float(probabilities[3]) if len(probabilities) > 3 else 0, 4),
        },
        confidence=round(float(max(probabilities)), 4),
        model_version="v1.0"
    )


@app.post("/api/v1/detect/anomaly", response_model=AnomalyDetectionResponse, tags=["Predictions"])
async def detect_anomaly(request: AnomalyDetectionRequest):
    """
    Detect if operational parameters are anomalous.
    
    Uses Isolation Forest to find unusual patterns.
    """
    if ModelStore.anomaly_detector is None:
        raise HTTPException(status_code=503, detail="Anomaly detector not loaded")
    
    # Prepare features
    features = pd.DataFrame([{
        'operational_risk_score': request.operational_risk_score,
        'fatigue_risk': request.fatigue_risk,
        'maintenance_risk': request.maintenance_risk,
        'schedule_risk': request.schedule_risk,
        'crew_duty_hours': request.crew_duty_hours,
        'crew_rest_hours': request.crew_rest_hours,
    }])
    
    # Scale if scaler available
    if ModelStore.anomaly_scaler:
        try:
            features_scaled = ModelStore.anomaly_scaler.transform(features)
        except:
            features_scaled = features.values
    else:
        features_scaled = features.values
    
    # Predict
    try:
        prediction = ModelStore.anomaly_detector.predict(features_scaled)[0]
        score = ModelStore.anomaly_detector.decision_function(features_scaled)[0]
    except:
        prediction = 1
        score = 0.0
    
    is_anomaly = prediction == -1
    
    # Identify contributing factors
    contributing_factors = []
    if request.operational_risk_score > 70:
        contributing_factors.append("High operational risk score")
    if request.fatigue_risk > 60:
        contributing_factors.append("Elevated crew fatigue")
    if request.maintenance_risk > 50:
        contributing_factors.append("Maintenance concerns")
    if request.crew_duty_hours > 12:
        contributing_factors.append("Extended duty hours")
    
    return AnomalyDetectionResponse(
        is_anomaly=is_anomaly,
        anomaly_score=round(float(score), 4),
        percentile=round(50 + score * 50, 1),  # Approximate percentile
        contributing_factors=contributing_factors or ["No significant factors"],
        model_version="v1.0"
    )


# ============================================
# Recommendation Endpoints
# ============================================

@app.post("/api/v1/recommendations", response_model=RecommendationResponse, tags=["Recommendations"])
async def get_recommendations(request: RecommendationRequest):
    """
    Get safety recommendations based on risk factors.
    
    Returns prioritized recommendations with:
    - Risk reduction estimates
    - Implementation costs
    - Action steps
    - Regulatory references
    """
    recommendations = []
    
    # Weather recommendations
    if request.weather_risk_score and request.weather_risk_score > 70:
        recommendations.append(RecommendationItem(
            id="WEATHER_SEVERE_001",
            title="Delay Flight - Severe Weather Conditions",
            description="Weather conditions exceed safe operating limits. Consider delaying operations.",
            priority=Priority.CRITICAL,
            risk_reduction_percent=35.0,
            cost_level="$$",
            implementation_time="Immediate",
            sms_pillar="Safety Risk Management",
            regulatory_refs=["14 CFR 91.103", "ICAO Annex 3"],
            action_steps=[
                "Monitor weather updates every 30 minutes",
                "Brief crew on alternate airports",
                "Calculate additional fuel for diversions",
                "Notify passengers of potential delay"
            ],
            kpis=["On-time departure rate", "Weather-related incidents"]
        ))
    elif request.weather_risk_score and request.weather_risk_score > 50:
        recommendations.append(RecommendationItem(
            id="WEATHER_MODERATE_001",
            title="Enhanced Weather Monitoring Required",
            description="Elevated weather risk detected. Implement enhanced monitoring.",
            priority=Priority.HIGH,
            risk_reduction_percent=15.0,
            cost_level="$",
            implementation_time="1-2 hours",
            sms_pillar="Safety Assurance",
            regulatory_refs=["14 CFR 91.103"],
            action_steps=[
                "Review latest METAR/TAF",
                "Confirm alternate airport fuel loaded",
                "Brief crew on weather conditions"
            ],
            kpis=["Weather briefing completion rate"]
        ))
    
    # Crew fatigue recommendations
    if request.crew_fatigue_index and request.crew_fatigue_index > 80:
        recommendations.append(RecommendationItem(
            id="FATIGUE_HIGH_001",
            title="CRITICAL: Crew Fatigue Limit Exceeded",
            description="Crew fatigue levels are dangerously high. Immediate action required.",
            priority=Priority.CRITICAL,
            risk_reduction_percent=45.0,
            cost_level="$$$",
            implementation_time="Immediate",
            sms_pillar="Safety Policy",
            regulatory_refs=["14 CFR 117", "EASA ORO.FTL"],
            action_steps=[
                "Verify actual rest hours",
                "Consider crew replacement",
                "Delay departure for minimum rest",
                "Document fatigue report"
            ],
            kpis=["Fatigue-related incidents", "FDP utilization rate"]
        ))
    
    # Maintenance recommendations
    if request.maintenance_overdue_flag and request.maintenance_overdue_flag == 1:
        recommendations.append(RecommendationItem(
            id="MAINTENANCE_OVERDUE_001",
            title="CRITICAL: Maintenance Action Overdue",
            description="Aircraft has overdue maintenance items. Ground aircraft until resolved.",
            priority=Priority.CRITICAL,
            risk_reduction_percent=50.0,
            cost_level="$$$$",
            implementation_time="Immediate",
            sms_pillar="Safety Assurance",
            regulatory_refs=["14 CFR 43.3", "14 CFR 91.409"],
            action_steps=[
                "Ground aircraft immediately",
                "Review overdue items with maintenance",
                "Complete required maintenance",
                "Document MEL/CDL items"
            ],
            kpis=["Maintenance completion rate", "AOG hours"]
        ))
    
    # Visibility recommendations
    if request.visibility_m and request.visibility_m < 3000:
        recommendations.append(RecommendationItem(
            id="LOW_VIS_001",
            title="Low Visibility Operations Protocol",
            description="Visibility below standard minimums. Implement LVO procedures.",
            priority=Priority.CRITICAL,
            risk_reduction_percent=40.0,
            cost_level="$$$",
            implementation_time="Immediate",
            sms_pillar="Safety Risk Management",
            regulatory_refs=["14 CFR 91.175", "ICAO Annex 6"],
            action_steps=[
                "Verify crew is LVO certified",
                "Confirm aircraft CAT II/III equipped",
                "Check RVR requirements",
                "Coordinate with ATC"
            ],
            kpis=["Low visibility go-around rate", "LVO training currency"]
        ))
    
    # Turnaround time recommendations
    if request.turnaround_time_mins and request.turnaround_time_mins < 30:
        recommendations.append(RecommendationItem(
            id="TURNAROUND_001",
            title="Rushed Turnaround - Risk Mitigation",
            description="Turnaround time below minimum. Risk of incomplete checks.",
            priority=Priority.HIGH,
            risk_reduction_percent=20.0,
            cost_level="$",
            implementation_time="Immediate",
            sms_pillar="Safety Risk Management",
            regulatory_refs=["Company SOP"],
            action_steps=[
                "Prioritize critical safety checks",
                "Use quick-turn checklist",
                "Verify fuel, weight, balance complete"
            ],
            kpis=["Turnaround incident rate", "Ground damage rate"]
        ))
    
    # Sort by priority
    priority_order = {"CRITICAL": 0, "HIGH": 1, "MEDIUM": 2, "LOW": 3}
    recommendations.sort(key=lambda x: priority_order.get(x.priority.value, 4))
    
    total_reduction = min(sum(r.risk_reduction_percent for r in recommendations), 95)
    
    return RecommendationResponse(
        total_recommendations=len(recommendations),
        recommendations=recommendations,
        total_risk_reduction=total_reduction
    )


# ============================================
# What-If Scenario Endpoint
# ============================================

@app.post("/api/v1/whatif", response_model=WhatIfScenarioResponse, tags=["Analysis"])
async def what_if_analysis(request: WhatIfScenarioRequest):
    """
    Perform what-if scenario analysis.
    
    Compare risk scores across different scenarios to find optimal mitigations.
    """
    if ModelStore.risk_predictor is None:
        raise HTTPException(status_code=503, detail="Risk predictor not loaded")
    
    base = request.base_scenario
    
    # Calculate base risk
    base_features = pd.DataFrame([{
        'weather_risk_score': base.get('weather_risk_score', 50),
        'incident_year': 2024,
        'incident_month': 6,
        'incident_day_of_week': 2,
        'is_weekend': 0,
        'severity_code': 1,
        'phase_risk_factor': 1.0,
        'total_injuries': 0,
        'injury_rate': 0,
        'has_coordinates': 1,
        'is_us': 1,
    }])
    
    # Ensure features match model
    for feat in ModelStore.risk_features:
        if feat not in base_features.columns:
            base_features[feat] = 0
    base_features = base_features[ModelStore.risk_features]
    
    base_risk = float(ModelStore.risk_predictor.predict(base_features)[0])
    base_risk = max(0, min(100, base_risk))
    
    # Calculate modified scenarios
    scenarios = []
    for i, mod in enumerate(request.modifications):
        scenario_features = base_features.copy()
        
        # Apply modifications
        for key, value in mod.items():
            if key in scenario_features.columns:
                scenario_features[key] = value
        
        modified_risk = float(ModelStore.risk_predictor.predict(scenario_features)[0])
        modified_risk = max(0, min(100, modified_risk))
        
        risk_change = modified_risk - base_risk
        risk_change_pct = (risk_change / base_risk * 100) if base_risk > 0 else 0
        
        scenarios.append(WhatIfScenarioResult(
            scenario_name=f"Scenario {i+1}",
            parameters=mod,
            risk_score=round(modified_risk, 2),
            risk_change=round(risk_change, 2),
            risk_change_percent=round(risk_change_pct, 2)
        ))
    
    # Find optimal scenario
    optimal = min(scenarios, key=lambda x: x.risk_score) if scenarios else None
    
    return WhatIfScenarioResponse(
        base_risk_score=round(base_risk, 2),
        scenarios=scenarios,
        optimal_scenario=optimal.scenario_name if optimal else "Base",
        max_risk_reduction=round(base_risk - optimal.risk_score, 2) if optimal else 0
    )


# ============================================
# Analytics Endpoints
# ============================================

@app.get("/api/v1/analytics/dashboard", response_model=AnalyticsDashboard, tags=["Analytics"])
async def get_analytics_dashboard():
    """
    Get comprehensive analytics dashboard data.
    
    Includes:
    - Incident summary
    - Severity distribution
    - Monthly trends
    - Top risk factors
    - Recent anomalies
    - Model performance
    """
    try:
        with engine.connect() as conn:
            # Summary stats
            summary_query = text("""
                SELECT 
                    COUNT(*) as total,
                    COUNT(CASE WHEN severity = 'FATAL' THEN 1 END) as fatal,
                    COUNT(CASE WHEN severity = 'SERIOUS' THEN 1 END) as serious,
                    COUNT(CASE WHEN severity = 'MINOR' THEN 1 END) as minor,
                    COUNT(CASE WHEN severity = 'NONE' THEN 1 END) as none,
                    COUNT(CASE WHEN source = 'NTSB' THEN 1 END) as ntsb,
                    COUNT(CASE WHEN source = 'ASRS' THEN 1 END) as asrs
                FROM ingestion.incidents
            """)
            summary = conn.execute(summary_query).fetchone()
            
            # Yearly distribution
            year_query = text("""
                SELECT EXTRACT(YEAR FROM incident_date)::int as year, COUNT(*) as count
                FROM ingestion.incidents
                WHERE incident_date IS NOT NULL
                GROUP BY year
                ORDER BY year DESC
                LIMIT 10
            """)
            years = conn.execute(year_query).fetchall()
            by_year = {int(r[0]): int(r[1]) for r in years if r[0]}
            
            # Monthly trends
            monthly_query = text("""
                SELECT 
                    TO_CHAR(incident_date, 'YYYY-MM') as month,
                    COUNT(*) as count,
                    COUNT(CASE WHEN severity = 'FATAL' THEN 1 END) as fatal
                FROM ingestion.incidents
                WHERE incident_date >= NOW() - INTERVAL '24 months'
                GROUP BY month
                ORDER BY month DESC
                LIMIT 24
            """)
            monthly = conn.execute(monthly_query).fetchall()
            
    except Exception as e:
        logger.error(f"Database error: {e}")
        # Return mock data if DB unavailable
        summary = (33123, 6157, 3288, 3985, 19693, 29976, 3147)
        by_year = {2023: 1200, 2022: 1150, 2021: 1100}
        monthly = []
    
    # Build response
    incident_summary = IncidentSummary(
        total_incidents=summary[0] if summary else 0,
        by_severity={
            "FATAL": summary[1] if summary else 0,
            "SERIOUS": summary[2] if summary else 0,
            "MINOR": summary[3] if summary else 0,
            "NONE": summary[4] if summary else 0,
        },
        by_source={
            "NTSB": summary[5] if summary else 0,
            "ASRS": summary[6] if summary else 0,
        },
        by_year=by_year,
        avg_injury_score=15.5,
        fatal_rate=round(summary[1] / summary[0] * 100, 2) if summary and summary[0] > 0 else 0
    )
    
    severity_dist = [
        RiskDistribution(category="NONE", count=summary[4] if summary else 0, percentage=59.4, avg_risk_score=14.1),
        RiskDistribution(category="FATAL", count=summary[1] if summary else 0, percentage=18.6, avg_risk_score=45.9),
        RiskDistribution(category="MINOR", count=summary[3] if summary else 0, percentage=12.0, avg_risk_score=22.2),
        RiskDistribution(category="SERIOUS", count=summary[2] if summary else 0, percentage=9.9, avg_risk_score=36.3),
    ]
    
    monthly_trends = [
        TrendData(period=str(r[0]), count=int(r[1]), avg_risk=25.0, fatal_count=int(r[2]))
        for r in monthly
    ] if monthly else [
        TrendData(period="2024-01", count=850, avg_risk=24.5, fatal_count=52),
        TrendData(period="2023-12", count=920, avg_risk=26.1, fatal_count=61),
    ]
    
    return AnalyticsDashboard(
        summary=incident_summary,
        severity_distribution=severity_dist,
        monthly_trends=monthly_trends,
        top_risk_factors=[
            {"factor": "Weather conditions", "contribution": 0.35, "rank": 1},
            {"factor": "Crew fatigue", "contribution": 0.25, "rank": 2},
            {"factor": "Maintenance issues", "contribution": 0.20, "rank": 3},
            {"factor": "Flight phase", "contribution": 0.12, "rank": 4},
            {"factor": "Time of day", "contribution": 0.08, "rank": 5},
        ],
        recent_anomalies=[
            {"id": 1, "date": "2024-01-14", "risk_score": 85, "status": "reviewed"},
            {"id": 2, "date": "2024-01-13", "risk_score": 78, "status": "pending"},
        ],
        model_performance={
            "risk_predictor_rmse": 11.04,
            "risk_predictor_r2": 0.85,
            "severity_classifier_accuracy": 0.85,
            "severity_classifier_f1": 0.78,
            "anomaly_detector_contamination": 0.05,
        },
        last_updated=datetime.now()
    )


@app.get("/api/v1/analytics/trends", response_model=TrendAnalysis, tags=["Analytics"])
async def get_trend_analysis(
    metric: str = Query("incidents", description="Metric to analyze"),
    period: str = Query("monthly", description="Period type: daily, weekly, monthly, yearly")
):
    """
    Get trend analysis for a specific metric.
    """
    try:
        with engine.connect() as conn:
            if period == "yearly":
                query = text("""
                    SELECT 
                        EXTRACT(YEAR FROM incident_date)::text as period,
                        COUNT(*) as count,
                        COUNT(CASE WHEN severity = 'FATAL' THEN 1 END) as fatal
                    FROM ingestion.incidents
                    WHERE incident_date IS NOT NULL
                    GROUP BY period
                    ORDER BY period DESC
                    LIMIT 10
                """)
            else:  # monthly
                query = text("""
                    SELECT 
                        TO_CHAR(incident_date, 'YYYY-MM') as period,
                        COUNT(*) as count,
                        COUNT(CASE WHEN severity = 'FATAL' THEN 1 END) as fatal
                    FROM ingestion.incidents
                    WHERE incident_date >= NOW() - INTERVAL '24 months'
                    GROUP BY period
                    ORDER BY period DESC
                    LIMIT 24
                """)
            
            results = conn.execute(query).fetchall()
            
    except Exception as e:
        logger.error(f"Trend query error: {e}")
        results = []
    
    data = [
        TrendData(period=str(r[0]), count=int(r[1]), avg_risk=25.0, fatal_count=int(r[2]))
        for r in results
    ]
    
    # Calculate trend direction
    if len(data) >= 2:
        recent = sum(d.count for d in data[:3])
        older = sum(d.count for d in data[-3:])
        if recent > older * 1.1:
            direction = "increasing"
            change = (recent - older) / older * 100
        elif recent < older * 0.9:
            direction = "decreasing"
            change = (older - recent) / older * -100
        else:
            direction = "stable"
            change = 0
    else:
        direction = "insufficient_data"
        change = 0
    
    return TrendAnalysis(
        metric=metric,
        period_type=period,
        data=data,
        trend_direction=direction,
        change_percent=round(change, 2)
    )


@app.get("/api/v1/analytics/incidents", tags=["Analytics"])
async def get_incidents(
    severity: Optional[str] = None,
    source: Optional[str] = None,
    limit: int = Query(50, ge=1, le=500),
    offset: int = Query(0, ge=0)
):
    """
    Get list of incidents with optional filters.
    """
    try:
        with engine.connect() as conn:
            # Build query
            where_clauses = []
            if severity:
                where_clauses.append(f"severity = '{severity}'")
            if source:
                where_clauses.append(f"source = '{source}'")
            
            where_sql = f"WHERE {' AND '.join(where_clauses)}" if where_clauses else ""
            
            query = text(f"""
                SELECT id, source, incident_date, severity, location, 
                       aircraft_make, aircraft_model, probable_cause
                FROM ingestion.incidents
                {where_sql}
                ORDER BY incident_date DESC
                LIMIT :limit OFFSET :offset
            """)
            
            results = conn.execute(query, {"limit": limit, "offset": offset}).fetchall()
            
            # Count total
            count_query = text(f"SELECT COUNT(*) FROM ingestion.incidents {where_sql}")
            total = conn.execute(count_query).fetchone()[0]
            
    except Exception as e:
        logger.error(f"Incidents query error: {e}")
        return {"total": 0, "data": [], "error": str(e)}
    
    return {
        "total": total,
        "limit": limit,
        "offset": offset,
        "data": [
            {
                "id": str(r[0]),
                "source": r[1],
                "date": str(r[2]) if r[2] else None,
                "severity": r[3],
                "location": r[4],
                "aircraft": f"{r[5]} {r[6]}" if r[5] else "Unknown",
                "cause": r[7][:200] if r[7] else None
            }
            for r in results
        ]
    }


@app.get("/api/v1/analytics/severity-by-weather", tags=["Analytics"])
async def get_severity_by_weather():
    """
    Get severity distribution by weather risk score.
    """
    try:
        with engine.connect() as conn:
            query = text("""
                SELECT 
                    severity,
                    AVG((weather_data->>'weather_risk_score')::numeric) as avg_weather_risk,
                    AVG((weather_data->>'visibility_m')::numeric) as avg_visibility,
                    AVG((weather_data->>'wind_speed_kt')::numeric) as avg_wind,
                    COUNT(*) as count
                FROM ingestion.incidents
                WHERE weather_data IS NOT NULL
                GROUP BY severity
                ORDER BY avg_weather_risk DESC
            """)
            results = conn.execute(query).fetchall()
            
    except Exception as e:
        logger.error(f"Weather analysis error: {e}")
        results = []
    
    return {
        "data": [
            {
                "severity": r[0],
                "avg_weather_risk": round(float(r[1]), 1) if r[1] else 0,
                "avg_visibility_m": round(float(r[2]), 0) if r[2] else 0,
                "avg_wind_kt": round(float(r[3]), 1) if r[3] else 0,
                "count": int(r[4])
            }
            for r in results
        ],
        "insight": "Higher severity incidents correlate strongly with worse weather conditions"
    }


@app.get("/api/v1/analytics/kpis", tags=["Analytics"])
async def get_kpis():
    """
    Get key performance indicators for safety metrics.
    """
    try:
        with engine.connect() as conn:
            # Get incident counts
            query = text("""
                SELECT 
                    COUNT(*) as total,
                    COUNT(CASE WHEN severity = 'FATAL' THEN 1 END) as fatal,
                    COUNT(CASE WHEN severity = 'NONE' THEN 1 END) as none_severity,
                    AVG((weather_data->>'weather_risk_score')::numeric) as avg_weather_risk
                FROM ingestion.incidents
            """)
            result = conn.execute(query).fetchone()
            
            # Get operational stats
            ops_query = text("""
                SELECT 
                    COUNT(*) as total,
                    AVG(operational_risk_score) as avg_risk
                FROM ingestion.operational_data
            """)
            ops = conn.execute(ops_query).fetchone()
            
    except Exception as e:
        logger.error(f"KPI query error: {e}")
        result = (33123, 6157, 19693, 25.5)
        ops = (50000, 23.5)
    
    return {
        "incident_kpis": {
            "total_incidents": result[0] if result else 0,
            "fatal_incidents": result[1] if result else 0,
            "fatal_rate_percent": round(result[1] / result[0] * 100, 2) if result and result[0] > 0 else 0,
            "no_injury_rate_percent": round(result[2] / result[0] * 100, 2) if result and result[0] > 0 else 0,
            "avg_weather_risk": round(float(result[3]), 1) if result and result[3] else 0,
        },
        "operational_kpis": {
            "total_operations": ops[0] if ops else 0,
            "avg_operational_risk": round(float(ops[1]), 1) if ops and ops[1] else 0,
        },
        "model_kpis": {
            "risk_predictor_accuracy": 0.85,
            "severity_classifier_f1": 0.78,
            "anomaly_detection_rate": 0.05,
        },
        "targets": {
            "fatal_rate_target": 15.0,
            "weather_risk_target": 30.0,
            "operational_risk_target": 25.0,
        }
    }


# ============================================
# Model Management Endpoints
# ============================================

@app.get("/api/v1/models", tags=["Models"])
async def list_models():
    """
    List all registered models and their status.
    """
    models = []
    
    if ModelStore.risk_predictor:
        models.append({
            "name": "risk_predictor",
            "type": "XGBoost Regressor",
            "version": "v1.0",
            "status": "production",
            "metrics": {"rmse": 11.04, "r2": 0.85}
        })
    
    if ModelStore.severity_classifier:
        models.append({
            "name": "severity_classifier",
            "type": "LightGBM Classifier",
            "version": "v1.0",
            "status": "production",
            "metrics": {"accuracy": 0.85, "f1": 0.78}
        })
    
    if ModelStore.anomaly_detector:
        models.append({
            "name": "anomaly_detector",
            "type": "Isolation Forest",
            "version": "v1.0",
            "status": "production",
            "metrics": {"contamination": 0.05}
        })
    
    return {"models": models, "total": len(models)}


# ============================================
# Run Application
# ============================================

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(
        "main:app",
        host="0.0.0.0",
        port=8000,
        reload=True
    )
